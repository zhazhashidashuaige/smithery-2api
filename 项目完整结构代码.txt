é¡¹ç›® 'smithery-2api' çš„ç»“æ„æ ‘:
ğŸ“‚ smithery-2api/
    ğŸ“„ .env
    ğŸ“„ .env.example
    ğŸ“„ Dockerfile
    ğŸ“„ docker-compose.yml
    ğŸ“„ main.py
    ğŸ“„ requirements.txt
    ğŸ“‚ app/
        ğŸ“‚ core/
            ğŸ“„ __init__.py
            ğŸ“„ config.py
        ğŸ“‚ providers/
            ğŸ“„ __init__.py
            ğŸ“„ base_provider.py
            ğŸ“„ smithery_provider.py
        ğŸ“‚ services/
            ğŸ“„ metrics_store.py
            ğŸ“„ session_manager.py
            ğŸ“„ tool_caller.py
        ğŸ“‚ frontend/
            ğŸ“„ dashboard.html
        ğŸ“‚ utils/
            ğŸ“„ token_counter.py
            ğŸ“„ sse_utils.py
================================================================================

--- æ–‡ä»¶è·¯å¾„: .env ---

# [è‡ªåŠ¨å¡«å……] smithery-2api ç”Ÿäº§ç¯å¢ƒé…ç½®
# è¯¥æ–‡ä»¶ç”± Genesis Protocol Â· Î© (Omega) ç‰ˆè‡ªåŠ¨ç”Ÿæˆå’Œä¿®æ­£

# --- å®‰å…¨é…ç½® ---
# ç”¨äºä¿æŠ¤æ‚¨çš„ API æœåŠ¡çš„è®¿é—®å¯†é’¥ï¼Œè¯·æŒ‰éœ€ä¿®æ”¹ä¸ºæ‚¨è‡ªå·±çš„å¤æ‚å¯†é’¥ã€‚
API_MASTER_KEY=1

# --- ç«¯å£é…ç½® ---
# FastAPI å¯¹å¤–æš´éœ²çš„ç«¯å£ï¼ˆDocker Compose å¯é€‰é…ç½®ï¼‰
APP_PORT=8000

# --- Smithery.ai å‡­è¯ (æ”¯æŒå¤šè´¦å·) ---
# æ ¼å¼å·²æ ¹æ®æœ€ç»ˆæ–¹æ¡ˆè‡ªåŠ¨è½¬æ¢ã€‚è¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹æ­¤ JSON ç»“æ„ã€‚
# æ‚¨å¯ä»¥æ·»åŠ  SMITHERY_COOKIE_2, SMITHERY_COOKIE_3 ç­‰æ¥å¯ç”¨è½®è¯¢
SMITHERY_COOKIE_1='{"access_token":"eyJhbGciOiJIUzI1NiIsImtpZCI6Ikk4N0N0U1U2UHFrWlVVV0QiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3NwamF3YmZwd2V6amZtaWNvcHNsLnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiI1OTA1ZjZiNC1kNzRmLTQ2YjQtOWI0Zi05ZGJiY2NiMjliZWUiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzYwNzkxMjY1LCJpYXQiOjE3NjA3ODc2NjUsImVtYWlsIjoiMjg2NDQ2MDQ1OUBxcS5jb20iLCJwaG9uZSI6IiIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6ImdpdGh1YiIsInByb3ZpZGVycyI6WyJnaXRodWIiXX0sInVzZXJfbWV0YWRhdGEiOnsiYXZhdGFyX3VybCI6Imh0dHBzOi8vYXZhdGFycy5naXRodWJ1c2VyY29udGVudC5jb20vdS8xMjg4ODAyMDY_dj00IiwiZW1haWwiOiIyODY0NDYwNDU5QHFxLmNvbSIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJmdWxsX25hbWUiOiJDaGluZXNlLXRpbmdmZW5nIiwiaXNzIjoiaHR0cHM6Ly9hcGkuZ2l0aHViLmNvbSIsIm5hbWUiOiJDaGluZXNlLXRpbmdmZW5nIiwicGhvbmVfdmVyaWZpZWQiOmZhbHNlLCJwcmVmZXJyZWRfdXNlcm5hbWUiOiJsekE2IiwicHJvdmlkZXJfaWQiOiIxMjg4ODAyMDYiLCJzdWIiOiIxMjg4ODAyMDYiLCJ1c2VyX25hbWUiOiJsekE2In0sInJvbGUiOiJhdXRoZW50aWNhdGVkIiwiYWFsIjoiYWFsMSIsImFtciI6W3sibWV0aG9kIjoib2F1dGgiLCJ0aW1lc3RhbXAiOjE3NTkxNjA1NDF9XSwic2Vzc2lvbl9pZCI6IjQxM2E0NTJjLTFjYjgtNDY5OC04YjYxLTQxYjQ3YjU5YjE4NyIsImlzX2Fub255bW91cyI6ZmFsc2V9.L4EcDMbtxobs_PpoPjpIfqvLxoIDyo_fFiLD4PyMwDo","token_type":"bearer","expires_in":3600,"expires_at":1760791265,"refresh_token":"4jxavtzs4tbw","user":{"id":"5905f6b4-d74f-46b4-9b4f-9dbbccb29bee","aud":"authenticated","role":"authenticated","email":"2864460459@qq.com","email_confirmed_at":"2025-09-29T15:42:18.953805Z","phone":"","confirmed_at":"2025-09-29T15:42:18.953805Z","last_sign_in_at":"2025-09-29T15:42:21.761683Z","app_metadata":{"provider":"github","providers":["github"]},"user_metadata":{"avatar_url":"https://avatars.githubusercontent.com/u/128880206?v=4","email":"2864460459@qq.com","email_verified":true,"full_name":"Chinese-tingfeng","iss":"https://api.github.com","name":"Chinese-tingfeng","phone_verified":false,"preferred_username":"lzA6","provider_id":"128880206","sub":"128880206","user_name":"lzA6"},"identities":[{"identity_id":"f3fd9077-2a8c-422d-b607-0a721f4ab6c2","id":"128880206","user_id":"5905f6b4-d74f-46b4-9b4f-9dbbccb29bee","identity_data":{"avatar_url":"https://avatars.githubusercontent.com/u/128880206?v=4","email":"2864460459@qq.com","email_verified":true,"full_name":"Chinese-tingfeng","iss":"https://api.github.com","name":"Chinese-tingfeng","phone_verified":false,"preferred_username":"lzA6","provider_id":"128880206","sub":"128880206","user_name":"lzA6"},"provider":"github","last_sign_in_at":"2025-09-29T15:42:18.9472Z","created_at":"2025-09-29T15:42:18.947275Z","updated_at":"2025-09-29T15:42:18.947275Z","email":"2864460459@qq.com"}],"created_at":"2025-09-29T15:42:18.943571Z","updated_at":"2025-10-18T11:41:04.939715Z","is_anonymous":false}}'

# --- ä¼šè¯ç®¡ç† ---
# å¯¹è¯å†å²åœ¨å†…å­˜ä¸­çš„ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
SESSION_CACHE_TTL=3600


--- æ–‡ä»¶è·¯å¾„: .env.example ---

# ====================================================================
# smithery-2api é…ç½®æ–‡ä»¶æ¨¡æ¿
# ====================================================================
#
# è¯·å°†æ­¤æ–‡ä»¶é‡å‘½åä¸º ".env" å¹¶å¡«å…¥æ‚¨çš„å‡­è¯ã€‚
#

# --- æ ¸å¿ƒå®‰å…¨é…ç½® (å¿…é¡»è®¾ç½®) ---
# ç”¨äºä¿æŠ¤æ‚¨ API æœåŠ¡çš„è®¿é—®å¯†é’¥ã€‚
API_MASTER_KEY=sk-smithery-2api-default-key-please-change-me

# --- éƒ¨ç½²é…ç½® (å¯é€‰) ---
# FastAPI å¯¹å¤–æš´éœ²çš„ç«¯å£ï¼ˆDocker Compose å¯é€‰é…ç½®ï¼‰
APP_PORT=8000

# --- Smithery.ai å‡­è¯ (å¿…é¡»è®¾ç½®) ---
# è¯·ä»æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­è·å–å®Œæ•´çš„ Cookie å­—ç¬¦ä¸²ã€‚
# æ”¯æŒå¤šè´¦å·è½®è¯¢ï¼Œåªéœ€æŒ‰æ ¼å¼æ·»åŠ  SMITHERY_COOKIE_2, SMITHERY_COOKIE_3, ...
SMITHERY_COOKIE_1="åœ¨æ­¤å¤„ç²˜è´´æ‚¨çš„å®Œæ•´ Cookie å­—ç¬¦ä¸²"

# --- ä¼šè¯ç®¡ç† (å¯é€‰) ---
# å¯¹è¯å†å²åœ¨å†…å­˜ä¸­çš„ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
SESSION_CACHE_TTL=3600


--- æ–‡ä»¶è·¯å¾„: Dockerfile ---

# ====================================================================
# Dockerfile for smithery-2api (v1.0 - Genesis Omega Edition)
# ====================================================================

FROM python:3.10-slim

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
WORKDIR /app

# å®‰è£… Python ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¹¶åˆ‡æ¢åˆ°é root ç”¨æˆ·
RUN useradd --create-home appuser && \
    chown -R appuser:appuser /app
USER appuser

# æš´éœ²ç«¯å£å¹¶å¯åŠ¨
EXPOSE 8000
CMD ["sh", "-c", "uvicorn main:app --host 0.0.0.0 --port ${PORT:-8000} --workers 1"]


--- æ–‡ä»¶è·¯å¾„: docker-compose.yml ---

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: smithery-2api-app
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "${APP_PORT:-8000}:8000"


--- æ–‡ä»¶è·¯å¾„: main.py ---
import logging
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from functools import lru_cache
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, Depends, Header, Query
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse

from app.core.config import settings
from app.providers.smithery_provider import SmitheryProvider
from app.services.metrics_store import metrics_store

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

provider = SmitheryProvider()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info(f"åº”ç”¨å¯åŠ¨ä¸­... {settings.APP_NAME} v{settings.APP_VERSION}")
    logger.info("æœåŠ¡å·²è¿›å…¥ 'Cloudscraper' æ¨¡å¼ï¼Œå°†è‡ªåŠ¨å¤„ç† Cloudflare æŒ‘æˆ˜ã€‚")
    logger.info(
        "æœåŠ¡å°†åœ¨ http://0.0.0.0:%s ä¸Šå¯ç”¨ (å¯é€šè¿‡ PORT ç¯å¢ƒå˜é‡è¦†ç›–)",
        settings.runtime_port,
    )
    yield
    logger.info("åº”ç”¨å…³é—­ã€‚")

app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description=settings.DESCRIPTION,
    lifespan=lifespan
)


@lru_cache()
def _load_dashboard_html() -> str:
    dashboard_path = Path(__file__).resolve().parent / "app" / "frontend" / "dashboard.html"
    if dashboard_path.exists():
        return dashboard_path.read_text(encoding="utf-8")
    logger.warning("æœªæ‰¾åˆ° dashboard.htmlï¼Œè¿”å›å ä½é¡µé¢ã€‚")
    return "<html><body><h1>Dashboard æœªæ‰¾åˆ°</h1></body></html>"


def _parse_time_param(value: Optional[str]) -> Optional[float]:
    if value is None:
        return None

    candidate = value.strip()
    if not candidate:
        return None

    try:
        normalized = candidate.replace("Z", "+00:00")
        dt = datetime.fromisoformat(normalized)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        else:
            dt = dt.astimezone(timezone.utc)
        return dt.timestamp()
    except ValueError:
        try:
            return float(candidate)
        except ValueError as exc:
            raise HTTPException(status_code=400, detail=f"æ— æ³•è§£ææ—¶é—´å‚æ•°: {value}") from exc


def _to_iso(timestamp: Optional[float]) -> Optional[str]:
    if timestamp is None:
        return None
    return datetime.fromtimestamp(timestamp, tz=timezone.utc).isoformat()

async def verify_api_key(authorization: Optional[str] = Header(None)):
    if settings.API_MASTER_KEY and settings.API_MASTER_KEY != "1":
        if not authorization or "bearer" not in authorization.lower():
            raise HTTPException(status_code=401, detail="éœ€è¦ Bearer Token è®¤è¯ã€‚")
        token = authorization.split(" ")[-1]
        if token != settings.API_MASTER_KEY:
            raise HTTPException(status_code=403, detail="æ— æ•ˆçš„ API Keyã€‚")

@app.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request) -> StreamingResponse:
    try:
        request_data = await request.json()
        return await provider.chat_completion(request_data)
    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.get("/v1/models", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def list_models():
    return await provider.get_models()


@app.get("/metrics/requests", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def get_request_metrics(
    start: Optional[str] = Query(None, description="èµ·å§‹æ—¶é—´ (ISO8601 æˆ– UNIX ç§’)"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¶é—´ (ISO8601 æˆ– UNIX ç§’)"),
    limit: int = Query(100, ge=1, le=1000, description="è¿”å›è®°å½•çš„æœ€å¤§æ¡æ•° (é»˜è®¤ 100)"),
):
    start_ts = _parse_time_param(start)
    end_ts = _parse_time_param(end)

    if start_ts and end_ts and start_ts > end_ts:
        raise HTTPException(status_code=400, detail="èµ·å§‹æ—¶é—´ä¸èƒ½æ™šäºç»“æŸæ—¶é—´ã€‚")

    records = metrics_store.list_records(start=start_ts, end=end_ts)
    records.sort(key=lambda item: item.get("completed_at") or 0, reverse=True)
    if limit:
        records = records[:limit]

    formatted = []
    for record in records:
        formatted.append({
            "id": record.get("id"),
            "model": record.get("model"),
            "prompt_tokens": record.get("prompt_tokens", 0),
            "completion_tokens": record.get("completion_tokens", 0),
            "total_tokens": record.get("total_tokens", 0),
            "duration_ms": record.get("duration_ms", 0.0),
            "status": record.get("status", "unknown"),
            "error_message": record.get("error_message"),
            "started_at": _to_iso(record.get("started_at")),
            "completed_at": _to_iso(record.get("completed_at")),
        })

    return JSONResponse(content={"data": formatted})


@app.get("/metrics/summary", dependencies=[Depends(verify_api_key)], response_class=JSONResponse)
async def get_metrics_summary(
    start: Optional[str] = Query(None, description="èµ·å§‹æ—¶é—´ (ISO8601 æˆ– UNIX ç§’)"),
    end: Optional[str] = Query(None, description="ç»“æŸæ—¶é—´ (ISO8601 æˆ– UNIX ç§’)"),
):
    start_ts = _parse_time_param(start)
    end_ts = _parse_time_param(end)

    if start_ts and end_ts and start_ts > end_ts:
        raise HTTPException(status_code=400, detail="èµ·å§‹æ—¶é—´ä¸èƒ½æ™šäºç»“æŸæ—¶é—´ã€‚")

    summary = metrics_store.aggregate(start=start_ts, end=end_ts)
    summary.update({
        "window_start": _to_iso(start_ts) if start_ts else None,
        "window_end": _to_iso(end_ts) if end_ts else None,
    })

    return JSONResponse(content=summary)


@app.get("/dashboard", summary="å¯è§†åŒ–ç›‘æ§é¢æ¿", response_class=HTMLResponse)
async def dashboard() -> HTMLResponse:
    return HTMLResponse(content=_load_dashboard_html())


@app.get("/", summary="æ ¹è·¯å¾„")
def root():
    return {"message": f"æ¬¢è¿æ¥åˆ° {settings.APP_NAME} v{settings.APP_VERSION}. æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚"}

--- æ–‡ä»¶è·¯å¾„: requirements.txt ---

fastapi
uvicorn[standard]
pydantic-settings
python-dotenv
cloudscraper
cachetools
httpx
tiktoken


--- æ–‡ä»¶è·¯å¾„: app\core\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\core\config.py ---

import os
import json
import logging
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing import List, Optional, Dict

# è·å–ä¸€ä¸ªæ—¥å¿—è®°å½•å™¨å®ä¾‹
logger = logging.getLogger(__name__)

class AuthCookie:
    """
    å¤„ç†å¹¶ç”Ÿæˆ Smithery.ai æ‰€éœ€çš„è®¤è¯ Cookieã€‚
    å®ƒå°† .env æ–‡ä»¶ä¸­çš„ JSON å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸€ä¸ªæ ‡å‡†çš„ HTTP Cookie å¤´éƒ¨å­—ç¬¦ä¸²ã€‚
    """
    def __init__(self, json_string: str):
        try:
            # 1. è§£æä» .env æ–‡ä»¶è¯»å–çš„ JSON å­—ç¬¦ä¸²
            data = json.loads(json_string)
            self.access_token = data.get("access_token")
            self.refresh_token = data.get("refresh_token")
            self.expires_at = data.get("expires_at", 0)
            
            if not self.access_token:
                raise ValueError("Cookie JSON ä¸­ç¼ºå°‘ 'access_token'")

            # 2. æ„é€ å°†è¦æ”¾å…¥ Cookie header çš„å€¼éƒ¨åˆ† (å®ƒæœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ª JSON)
            #    æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªåŒ…å« Supabase auth éœ€è¦çš„æ ¸å¿ƒå­—æ®µ
            cookie_value_data = {
                "access_token": self.access_token,
                "refresh_token": self.refresh_token,
                "token_type": data.get("token_type", "bearer"),
                "expires_in": data.get("expires_in", 3600),
                "expires_at": self.expires_at,
                "user": data.get("user")
            }
            
            # 3. æ„é€ å®Œæ•´çš„ Cookie é”®å€¼å¯¹å­—ç¬¦ä¸²
            #    Smithery.ai ä½¿ç”¨çš„ Supabase project_ref æ˜¯ 'spjawbfpwezjfmicopsl'
            project_ref = "spjawbfpwezjfmicopsl"
            cookie_key = f"sb-{project_ref}-auth-token"
            # å°†å€¼éƒ¨åˆ†è½¬æ¢ä¸ºç´§å‡‘çš„ JSON å­—ç¬¦ä¸²
            cookie_value = json.dumps(cookie_value_data, separators=(',', ':'))
            
            # æœ€ç»ˆç”¨äº HTTP Header çš„å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "key=value"
            self.header_cookie_string = f"{cookie_key}={cookie_value}"

        except json.JSONDecodeError as e:
            raise ValueError(f"æ— æ³•ä»æä¾›çš„å­—ç¬¦ä¸²ä¸­è§£æè®¤è¯ JSON: {e}")
        except Exception as e:
            raise ValueError(f"åˆå§‹åŒ– AuthCookie æ—¶å‡ºé”™: {e}")

    def __repr__(self):
        return f"<AuthCookie expires_at={self.expires_at}>"


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding='utf-8',
        extra="ignore"
    )

    APP_NAME: str = "smithery-2api"
    APP_VERSION: str = "1.0.0"
    DESCRIPTION: str = "ä¸€ä¸ªå°† smithery.ai è½¬æ¢ä¸ºå…¼å®¹ OpenAI æ ¼å¼ API çš„é«˜æ€§èƒ½ä»£ç†ï¼Œæ”¯æŒå¤šè´¦å·ã€ä¸Šä¸‹æ–‡å’Œå·¥å…·è°ƒç”¨ã€‚"

    CHAT_API_URL: str = "https://smithery.ai/api/chat"
    TOKEN_REFRESH_URL: str = "https://spjawbfpwezjfmicopsl.supabase.co/auth/v1/token?grant_type=refresh_token"
    SUPABASE_API_KEY: str = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNwamF3YmZwd2V6amZtaWNvcHNsIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzQxNDc0MDUsImV4cCI6MjA0OTcyMzQwNX0.EBIg7_F2FZh4KZ3UNwZdBRjpp2fgHqXGJOvOSQ053MU"

    API_MASTER_KEY: Optional[str] = None
    
    AUTH_COOKIES: List[AuthCookie] = []

    API_REQUEST_TIMEOUT: int = 180
    SESSION_CACHE_TTL: int = 3600

    DEFAULT_SERVICE_PORT: int = 8000

    KNOWN_MODELS: List[str] = [
        "claude-haiku-4.5", "claude-sonnet-4.5", "gpt-5", "gpt-5-mini", 
        "gpt-5-nano", "gemini-2.5-flash-lite", "gemini-2.5-pro", "glm-4.6", 
        "grok-4-fast-non-reasoning", "grok-4-fast-reasoning", "kimi-k2", "deepseek-reasoner"
    ]

    def __init__(self, **values):
        super().__init__(**values)
        # ä»ç¯å¢ƒå˜é‡ SMITHERY_COOKIE_1, SMITHERY_COOKIE_2, ... åŠ è½½ cookies
        i = 1
        while True:
            cookie_str = os.getenv(f"SMITHERY_COOKIE_{i}")
            if cookie_str:
                try:
                    # ä½¿ç”¨ AuthCookie ç±»æ¥è§£æå’Œå¤„ç† cookie å­—ç¬¦ä¸²
                    self.AUTH_COOKIES.append(AuthCookie(cookie_str))
                except ValueError as e:
                    logger.warning(f"æ— æ³•åŠ è½½æˆ–è§£æ SMITHERY_COOKIE_{i}: {e}")
                i += 1
            else:
                break
        
        if not self.AUTH_COOKIES:
            raise ValueError("å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­è‡³å°‘é…ç½®ä¸€ä¸ªæœ‰æ•ˆçš„ SMITHERY_COOKIE_1")

    @property
    def runtime_port(self) -> int:
        raw_port = os.getenv("PORT")
        if not raw_port:
            return self.DEFAULT_SERVICE_PORT
        try:
            return int(raw_port)
        except ValueError:
            logger.warning("PORT ç¯å¢ƒå˜é‡ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ï¼Œå·²å›é€€åˆ°é»˜è®¤ç«¯å£ %s", self.DEFAULT_SERVICE_PORT)
            return self.DEFAULT_SERVICE_PORT

settings = Settings()


--- æ–‡ä»¶è·¯å¾„: app\providers\__init__.py ---



--- æ–‡ä»¶è·¯å¾„: app\providers\base_provider.py ---

from abc import ABC, abstractmethod
from typing import Dict, Any
from fastapi.responses import StreamingResponse, JSONResponse

class BaseProvider(ABC):
    @abstractmethod
    async def chat_completion(
        self,
        request_data: Dict[str, Any]
    ) -> StreamingResponse:
        pass

    @abstractmethod
    async def get_models(self) -> JSONResponse:
        pass


--- æ–‡ä»¶è·¯å¾„: app\providers\smithery_provider.py ---
import asyncio
import json
import time
import logging
import uuid
import cloudscraper
from typing import Dict, Any, AsyncGenerator, List

from fastapi.responses import StreamingResponse, JSONResponse

from app.core.config import settings
from app.providers.base_provider import BaseProvider
# ç§»é™¤äº†ä¸å†ä½¿ç”¨çš„ SessionManager
# from app.services.session_manager import SessionManager
from app.services.metrics_store import metrics_store
from app.utils.sse_utils import create_sse_data, create_chat_completion_chunk, DONE_CHUNK
from app.utils.token_counter import estimate_tokens_for_messages, estimate_tokens_for_text

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - [%(levelname)s] - %(message)s')
logger = logging.getLogger(__name__)

class SmitheryProvider(BaseProvider):
    def __init__(self):
        # self.session_manager = SessionManager() # ç§»é™¤ä¼šè¯ç®¡ç†å™¨
        self.scraper = cloudscraper.create_scraper()
        self.cookie_index = 0

    def _get_cookie(self) -> str:
        """ä»é…ç½®ä¸­è½®æ¢è·å–ä¸€ä¸ªæ ¼å¼æ­£ç¡®çš„ Cookie å­—ç¬¦ä¸²ã€‚"""
        auth_cookie_obj = settings.AUTH_COOKIES[self.cookie_index]
        self.cookie_index = (self.cookie_index + 1) % len(settings.AUTH_COOKIES)
        return auth_cookie_obj.header_cookie_string

    def _convert_messages_to_smithery_format(self, openai_messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å°†å®¢æˆ·ç«¯å‘æ¥çš„ OpenAI æ ¼å¼æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸º Smithery.ai åç«¯æ‰€éœ€çš„æ ¼å¼ã€‚
        ä¾‹å¦‚: {"role": "user", "content": "ä½ å¥½"} -> {"role": "user", "parts": [{"type": "text", "text": "ä½ å¥½"}]}
        """
        smithery_messages = []
        for msg in openai_messages:
            role = msg.get("role")
            content = msg.get("content", "")
            
            # å¿½ç•¥æ ¼å¼ä¸æ­£ç¡®æˆ–å†…å®¹ä¸ºç©ºçš„æ¶ˆæ¯
            if not role or not isinstance(content, str):
                continue
                
            smithery_messages.append({
                "role": role,
                "parts": [{"type": "text", "text": content}],
                "id": f"msg-{uuid.uuid4().hex[:16]}"
            })
        return smithery_messages

    async def chat_completion(self, request_data: Dict[str, Any]) -> StreamingResponse:
        """
        å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚ã€‚
        æ­¤å®ç°ä¸ºæ— çŠ¶æ€æ¨¡å¼ï¼Œå®Œå…¨ä¾èµ–å®¢æˆ·ç«¯å‘é€çš„å®Œæ•´å¯¹è¯å†å²ã€‚
        """
        
        # 1. ç›´æ¥ä»å®¢æˆ·ç«¯è¯·æ±‚ä¸­è·å–å®Œæ•´çš„æ¶ˆæ¯å†å²
        messages_from_client = request_data.get("messages", [])
        if not isinstance(messages_from_client, list):
            messages_from_client = []
        
        # 2. å°†å…¶è½¬æ¢ä¸º Smithery.ai åç«¯æ‰€éœ€çš„æ ¼å¼
        smithery_formatted_messages = self._convert_messages_to_smithery_format(messages_from_client)

        model = request_data.get("model", "claude-haiku-4.5")
        request_id = f"chatcmpl-{uuid.uuid4()}"
        prompt_tokens = estimate_tokens_for_messages(messages_from_client, model)
        start_time = time.time()
        collected_output: List[str] = []
        status = "success"
        error_message: str | None = None

        async def stream_generator() -> AsyncGenerator[bytes, None]:
            nonlocal status, error_message
            response = None

            try:
                # 3. ä½¿ç”¨è½¬æ¢åçš„æ¶ˆæ¯åˆ—è¡¨å‡†å¤‡è¯·æ±‚ä½“
                payload = self._prepare_payload(model, smithery_formatted_messages)
                headers = self._prepare_headers()

                logger.info("===================== [REQUEST TO SMITHERY (Stateless)] =====================")
                logger.info(f"URL: POST {settings.CHAT_API_URL}")
                logger.info(f"PAYLOAD:\n{json.dumps(payload, indent=2, ensure_ascii=False)}")
                logger.info("=====================================================================================")

                # ä½¿ç”¨ cloudscraper å‘é€è¯·æ±‚
                response = self.scraper.post(
                    settings.CHAT_API_URL,
                    headers=headers,
                    json=payload,
                    stream=True,
                    timeout=settings.API_REQUEST_TIMEOUT
                )

                if response.status_code != 200:
                    logger.error("==================== [RESPONSE FROM SMITHERY (ERROR)] ===================")
                    logger.error(f"STATUS CODE: {response.status_code}")
                    logger.error(f"RESPONSE BODY:\n{response.text}")
                    logger.error("=================================================================")

                response.raise_for_status()

                # 4. æµå¼å¤„ç†è¿”å›çš„æ•°æ®ï¼Œç¡®ä¿æŒ‰åˆ°è¾¾é¡ºåºå³æ—¶æ¨é€ç»™å®¢æˆ·ç«¯
                for raw_line in response.iter_lines(chunk_size=1):
                    if not raw_line:
                        # ä¸»åŠ¨è®©å‡ºäº‹ä»¶å¾ªç¯ï¼Œé¿å…é•¿æ—¶é—´å ç”¨å¯¼è‡´ç¼“å†²
                        await asyncio.sleep(0)
                        continue

                    line = raw_line.decode("utf-8", errors="ignore") if isinstance(raw_line, bytes) else raw_line
                    if not line.startswith("data:"):
                        continue

                    content = line[len("data:"):].strip()
                    if content == "[DONE]":
                        break

                    try:
                        data = json.loads(content)
                    except json.JSONDecodeError:
                        logger.warning("æ— æ³•è§£æ SSE æ•°æ®å—: %s", content)
                        continue

                    if data.get("type") == "text-delta":
                        delta_payload = data.get("delta", "")
                        if isinstance(delta_payload, dict):
                            delta_content = delta_payload.get("text", "")
                        else:
                            delta_content = delta_payload

                        if isinstance(delta_content, str):
                            collected_output.append(delta_content)
                        else:
                            normalized = str(delta_content)
                            collected_output.append(normalized)
                            delta_content = normalized

                        chunk = create_chat_completion_chunk(request_id, model, delta_content)
                        yield create_sse_data(chunk)
                        await asyncio.sleep(0)

                # 5. æ— çŠ¶æ€æ¨¡å¼ä¸‹ï¼Œæ— éœ€ä¿å­˜ä»»ä½•ä¼šè¯ï¼Œç›´æ¥å‘é€ç»“æŸæ ‡å¿—
                final_chunk = create_chat_completion_chunk(request_id, model, "", "stop")
                yield create_sse_data(final_chunk)
                await asyncio.sleep(0)
                yield DONE_CHUNK

            except Exception as e:
                logger.error(f"å¤„ç†æµæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
                status = "error"
                error_message = str(e)
                safe_error_message = f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}"
                error_chunk = create_chat_completion_chunk(request_id, model, safe_error_message, "stop")
                yield create_sse_data(error_chunk)
                yield DONE_CHUNK

            finally:
                completed_at = time.time()
                completion_text = "".join(collected_output)
                completion_tokens = estimate_tokens_for_text(completion_text, model)
                duration_ms = (completed_at - start_time) * 1000

                record = {
                    "id": request_id,
                    "model": model,
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": prompt_tokens + completion_tokens,
                    "started_at": start_time,
                    "completed_at": completed_at,
                    "duration_ms": duration_ms,
                    "status": status,
                    "error_message": error_message,
                }

                try:
                    metrics_store.add_record(record)
                except Exception:
                    logger.exception("è®°å½•è¯·æ±‚æŒ‡æ ‡å¤±è´¥")

                if response is not None:
                    response.close()

        return StreamingResponse(
            stream_generator(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache, no-transform",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    def _prepare_headers(self) -> Dict[str, str]:
        # åŒ…å«æˆ‘ä»¬ä¹‹å‰åˆ†æå‡ºçš„æ‰€æœ‰å¿…è¦è¯·æ±‚å¤´
        return {
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Content-Type": "application/json",
            "Cookie": self._get_cookie(),
            "Origin": "https://smithery.ai",
            "Referer": "https://smithery.ai/playground",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "priority": "u=1, i",
            "sec-ch-ua": '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-origin",
            "x-posthog-distinct-id": "5905f6b4-d74f-46b4-9b4f-9dbbccb29bee",
            "x-posthog-session-id": "0199f71f-8c42-7f9a-ba3a-ff5999dd444a",
            "x-posthog-window-id": "0199f71f-8c42-7f9a-ba3a-ff5ab5b20a8e",
        }

    def _prepare_payload(self, model: str, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        return {
            "messages": messages,
            "tools": [],
            "model": model,
            "systemPrompt": "You are a helpful assistant."
        }

    async def get_models(self) -> JSONResponse:
        model_data = {
            "object": "list",
            "data": [
                {"id": name, "object": "model", "created": int(time.time()), "owned_by": "lzA6"}
                for name in settings.KNOWN_MODELS
            ]
        }
        return JSONResponse(content=model_data)

--- æ–‡ä»¶è·¯å¾„: app\services\session_manager.py ---

from cachetools import TTLCache
from typing import List, Dict, Any
from app.core.config import settings

class SessionManager:
    def __init__(self):
        self.cache = TTLCache(maxsize=1024, ttl=settings.SESSION_CACHE_TTL)

    def get_messages(self, session_id: str) -> List[Dict[str, Any]]:
        """
        ä»ç¼“å­˜ä¸­è·å–æ¶ˆæ¯å†å²ã€‚
        è¿”å›åˆ—è¡¨çš„å‰¯æœ¬ä»¥é˜²æ­¢å¯¹ç¼“å­˜çš„æ„å¤–ä¿®æ”¹ã€‚
        """
        return self.cache.get(session_id, []).copy()

    def update_messages(self, session_id: str, messages: List[Dict[str, Any]]):
        """
        å°†æ›´æ–°åçš„æ¶ˆæ¯å†å²å­˜å›ç¼“å­˜ã€‚
        """
        self.cache[session_id] = messages


--- æ–‡ä»¶è·¯å¾„: app\services\tool_caller.py ---

import json
import logging
import random
from typing import List, Dict, Any
import cloudscraper

logger = logging.getLogger(__name__)

class ToolCaller:
    def __init__(self):
        self.mcp_url = "https://mcp.exa.ai/mcp"
        self.mcp_params = {
            "profile": "joyous-gull-NeZ2gW",
            "api_key": "fe5676be-931d-42e1-b5c9-90e94dce45ae"
        }
        self.scraper = cloudscraper.create_scraper()

    def get_tool_definitions(self) -> List[Dict[str, Any]]:
        # ä»æƒ…æŠ¥ä¸­æå–çš„å·¥å…·å®šä¹‰
        return [
            {"name":"resolve-library-id","title":"Resolve Context7 Library ID","description":"...","inputSchema":{}},
            {"name":"get-library-docs","title":"Get Library Docs","description":"...","inputSchema":{}},
            {"name":"web_search_exa","description":"...","inputSchema":{}},
            {"name":"get_code_context_exa","description":"...","inputSchema":{}}
        ]

    async def execute_tools(self, tool_calls: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        # æ­¤å‡½æ•°ç°åœ¨è¿”å›ä¸€ä¸ªå•ä¸€çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰å·¥å…·çš„ç»“æœ
        all_results_content = "Tool results:\n"
        
        for call in tool_calls:
            function_call = call.get("function", {})
            tool_name = function_call.get("name")
            tool_args_str = function_call.get("arguments", "{}")
            tool_call_id = call.get("id")

            logger.info(f"æ‰§è¡Œå·¥å…·è°ƒç”¨: {tool_name} with args {tool_args_str}")
            
            try:
                arguments = json.loads(tool_args_str)
                payload = {
                    "method": "tools/call",
                    "params": {"name": tool_name, "arguments": arguments},
                    "jsonrpc": "2.0",
                    "id": random.randint(1, 100)
                }
                
                response = self.scraper.post(self.mcp_url, params=self.mcp_params, json=payload)
                response.raise_for_status()
                
                result_content = "No content returned."
                for line in response.iter_lines():
                    if line.startswith(b"data:"):
                        content_str = line[len(b"data:"):].strip().decode('utf-8', errors='ignore')
                        if content_str == "[DONE]":
                            break
                        try:
                            data = json.loads(content_str)
                            if "result" in data and "content" in data["result"]:
                                # å°†ç»“æœæ ¼å¼åŒ–ä¸ºæ›´æ˜“è¯»çš„å­—ç¬¦ä¸²
                                result_content = json.dumps(data["result"]["content"], ensure_ascii=False, indent=2)
                                break
                        except json.JSONDecodeError:
                            logger.warning(f"MCP tool: æ— æ³•è§£æ SSE æ•°æ®å—: {content_str}")
                            continue
                
                all_results_content += f"\n--- Result for {tool_name} (call_id: {tool_call_id}) ---\n{result_content}\n"

            except Exception as e:
                logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
                error_str = f'{{"error": "Tool call failed", "details": "{str(e)}"}}'
                all_results_content += f"\n--- Error for {tool_name} (call_id: {tool_call_id}) ---\n{error_str}\n"

        # è¿”å›ä¸€ä¸ªå•ä¸€çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯å¤šä¸ª tool è§’è‰²çš„æ¶ˆæ¯
        return [{"role": "user", "content": all_results_content}]


--- æ–‡ä»¶è·¯å¾„: app\utils\sse_utils.py ---

import json
import time
from typing import Dict, Any, Optional

DONE_CHUNK = b"data: [DONE]\n\n"

def create_sse_data(data: Dict[str, Any]) -> bytes:
    return f"data: {json.dumps(data)}\n\n".encode('utf-8')

def create_chat_completion_chunk(
    request_id: str,
    model: str,
    content: str,
    finish_reason: Optional[str] = None
) -> Dict[str, Any]:
    return {
        "id": request_id,
        "object": "chat.completion.chunk",
        "created": int(time.time()),
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {"content": content},
                "finish_reason": finish_reason
            }
        ]
    }

--- æ–‡ä»¶è·¯å¾„: app\services\metrics_store.py ---
"""In-memory metrics collection for Smithery proxy requests."""
from __future__ import annotations

from collections import deque
from threading import Lock
from typing import Deque, Dict, List, Optional


class MetricsStore:
    """Thread-safe ring buffer storing recent request metrics."""

    def __init__(self, max_records: int = 1000):
        self._records: Deque[Dict] = deque(maxlen=max_records)
        self._lock = Lock()

    def add_record(self, record: Dict) -> None:
        with self._lock:
            self._records.append(record)

    def list_records(
        self,
        start: Optional[float] = None,
        end: Optional[float] = None,
    ) -> List[Dict]:
        with self._lock:
            snapshot = list(self._records)

        if start is None and end is None:
            return snapshot

        filtered: List[Dict] = []
        for record in snapshot:
            completed_at = record.get("completed_at")
            if completed_at is None:
                continue
            if start is not None and completed_at < start:
                continue
            if end is not None and completed_at > end:
                continue
            filtered.append(record)
        return filtered

    def aggregate(
        self,
        start: Optional[float] = None,
        end: Optional[float] = None,
    ) -> Dict[str, float]:
        records = self.list_records(start=start, end=end)

        prompt_tokens = sum(record.get("prompt_tokens", 0) for record in records)
        completion_tokens = sum(record.get("completion_tokens", 0) for record in records)
        total_tokens = prompt_tokens + completion_tokens

        request_count = len(records)
        success_count = sum(1 for record in records if record.get("status") == "success")
        error_count = request_count - success_count

        latencies = []
        for record in records:
            duration = record.get("duration_ms")
            if isinstance(duration, (int, float)):
                latencies.append(float(duration))
        average_latency_ms = sum(latencies) / len(latencies) if latencies else 0.0

        return {
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "request_count": request_count,
            "success_count": success_count,
            "error_count": error_count,
            "average_latency_ms": average_latency_ms,
        }


metrics_store = MetricsStore(max_records=5000)

--- æ–‡ä»¶è·¯å¾„: app\utils\token_counter.py ---
"""Utilities for estimating prompt and completion token counts."""
from __future__ import annotations

import re
from typing import Iterable, Dict, Any

try:
    import tiktoken  # type: ignore
except ImportError:  # pragma: no cover - optional dependency
    tiktoken = None  # type: ignore

_DEFAULT_ENCODING = "cl100k_base"
_TOKEN_PATTERN = re.compile(r"\w+|[^\w\s]", re.UNICODE)


def _estimate_with_tiktoken(text: str, model: str) -> int | None:
    if not tiktoken:
        return None

    encoding = None
    if model:
        try:
            encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            encoding = None
        except Exception:
            encoding = None
    if encoding is None:
        try:
            encoding = tiktoken.get_encoding(_DEFAULT_ENCODING)
        except Exception:
            return None

    try:
        return len(encoding.encode(text))
    except Exception:
        return None


def estimate_tokens_for_text(text: str, model: str = "") -> int:
    """Estimate the token count for a block of text.

    Attempts to use ``tiktoken`` when available for accurate counts on OpenAI
    compatible models. Falls back to a lightweight heuristic otherwise.
    """

    if not text:
        return 0

    normalized_text = text.strip()
    if not normalized_text:
        return 0

    tiktoken_estimate = _estimate_with_tiktoken(normalized_text, model)
    if tiktoken_estimate is not None:
        return tiktoken_estimate

    heuristic_tokens = _TOKEN_PATTERN.findall(normalized_text)
    if heuristic_tokens:
        return len(heuristic_tokens)

    # Final safety net: assume roughly 4 characters per token as a heuristic.
    return max(1, len(normalized_text) // 4)


def estimate_tokens_for_messages(messages: Iterable[Dict[str, Any]], model: str = "") -> int:
    """Estimate token usage for a list of OpenAI-style messages."""

    total = 0
    for message in messages:
        if not isinstance(message, dict):
            continue
        content = message.get("content")
        if isinstance(content, str):
            total += estimate_tokens_for_text(content, model)
    return total

--- æ–‡ä»¶è·¯å¾„: app\frontend\dashboard.html ---
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>Smithery ç›‘æ§é¢æ¿</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        :root {
            color-scheme: light dark;
            --bg-color: #f5f7fb;
            --text-color: #1c1f2b;
            --card-bg: #ffffff;
            --accent: #0066ff;
            --muted: #6b7280;
            --danger: #dc2626;
        }

        @media (prefers-color-scheme: dark) {
            :root {
                --bg-color: #0f172a;
                --text-color: #e2e8f0;
                --card-bg: #111827;
                --accent: #60a5fa;
                --muted: #94a3b8;
                --danger: #f87171;
            }
        }

        body {
            margin: 0;
            padding: 0;
            font-family: 'Segoe UI', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 32px 20px 60px;
        }

        header {
            display: flex;
            flex-direction: column;
            gap: 12px;
            margin-bottom: 28px;
        }

        header h1 {
            font-size: 2rem;
            margin: 0;
        }

        header p {
            margin: 0;
            color: var(--muted);
        }

        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
            gap: 16px;
            margin-bottom: 24px;
        }

        .card {
            background: var(--card-bg);
            border-radius: 14px;
            padding: 18px 20px;
            box-shadow: 0 10px 30px rgba(15, 23, 42, 0.08);
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        .card span.label {
            text-transform: uppercase;
            font-size: 0.75rem;
            letter-spacing: 0.08em;
            color: var(--muted);
        }

        .card strong {
            font-size: 1.8rem;
        }

        .controls {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 12px;
            margin-bottom: 20px;
            align-items: end;
        }

        .controls label {
            font-size: 0.85rem;
            color: var(--muted);
            display: block;
            margin-bottom: 6px;
        }

        .controls input, .controls button {
            width: 100%;
            padding: 10px 12px;
            border-radius: 10px;
            border: 1px solid rgba(148, 163, 184, 0.35);
            background: var(--card-bg);
            color: var(--text-color);
            box-sizing: border-box;
        }

        .controls button {
            background: var(--accent);
            color: #fff;
            border: none;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.1s ease, box-shadow 0.15s ease;
        }

        .controls button:hover {
            transform: translateY(-1px);
            box-shadow: 0 10px 20px rgba(37, 99, 235, 0.25);
        }

        .controls button.secondary {
            background: transparent;
            color: var(--accent);
            border: 1px solid var(--accent);
        }

        .status-bar {
            margin-bottom: 18px;
            font-size: 0.9rem;
            color: var(--muted);
            min-height: 20px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            border-radius: 14px;
            overflow: hidden;
            background: var(--card-bg);
            box-shadow: 0 16px 30px rgba(15, 23, 42, 0.08);
        }

        table th, table td {
            padding: 14px 16px;
            text-align: left;
            font-size: 0.92rem;
        }

        table thead {
            background: rgba(96, 165, 250, 0.18);
            color: var(--text-color);
        }

        table tbody tr:not(:last-child) {
            border-bottom: 1px solid rgba(148, 163, 184, 0.25);
        }

        table tbody tr.error {
            background: rgba(220, 38, 38, 0.08);
        }

        .api-key-wrapper {
            display: flex;
            flex-direction: column;
            gap: 8px;
            margin-bottom: 24px;
            background: var(--card-bg);
            padding: 16px 20px;
            border-radius: 14px;
            box-shadow: 0 12px 28px rgba(15, 23, 42, 0.08);
        }

        .api-key-wrapper label {
            font-size: 0.85rem;
            color: var(--muted);
        }

        .api-key-wrapper input {
            width: 100%;
            padding: 10px 12px;
            border-radius: 10px;
            border: 1px solid rgba(148, 163, 184, 0.35);
            background: var(--card-bg);
            color: var(--text-color);
        }

        .api-key-wrapper button {
            align-self: flex-start;
            padding: 8px 16px;
            border-radius: 10px;
            border: none;
            background: var(--accent);
            color: #fff;
            font-weight: 600;
            cursor: pointer;
        }

        .empty-state {
            padding: 28px;
            text-align: center;
            color: var(--muted);
        }

        .error-text {
            color: var(--danger);
            font-weight: 600;
        }

        @media (max-width: 720px) {
            header h1 {
                font-size: 1.5rem;
            }
            .card strong {
                font-size: 1.5rem;
            }
            table th, table td {
                padding: 10px 12px;
                font-size: 0.85rem;
            }
        }
    </style>
</head>
<body>
<div class="container">
    <header>
        <h1>Smithery è¯·æ±‚ç›‘æ§</h1>
        <p>å®æ—¶æ´å¯Ÿè¯·æ±‚è€—æ—¶ã€æ¨¡å‹ token ä½¿ç”¨æƒ…å†µä»¥åŠæ•´ä½“æ¶ˆè€—è¶‹åŠ¿ã€‚</p>
    </header>

    <section class="api-key-wrapper">
        <label for="apiKeyInput">ç”¨äºè®¿é—® /metrics æ¥å£çš„ Bearer Tokenï¼š</label>
        <input id="apiKeyInput" type="password" placeholder="sk-...">
        <button id="saveKey">ä¿å­˜å¯†é’¥</button>
        <small id="keyStatus" class="status-bar"></small>
    </section>

    <section class="controls">
        <div>
            <label for="startInput">èµ·å§‹æ—¶é—´ (æœ¬åœ°æ—¶åŒº)</label>
            <input type="datetime-local" id="startInput">
        </div>
        <div>
            <label for="endInput">ç»“æŸæ—¶é—´ (æœ¬åœ°æ—¶åŒº)</label>
            <input type="datetime-local" id="endInput">
        </div>
        <div>
            <label for="limitInput">æœ€å¤šè¿”å›æ¡æ•°</label>
            <input type="number" id="limitInput" value="100" min="1" max="1000">
        </div>
        <div>
            <button id="refreshButton">åˆ·æ–°æ•°æ®</button>
        </div>
        <div>
            <button id="autoRefreshButton" class="secondary">å¼€å¯è‡ªåŠ¨åˆ·æ–°</button>
        </div>
    </section>

    <div class="status-bar" id="statusBar"></div>

    <section class="card-grid" id="summaryCards">
        <article class="card">
            <span class="label">è¯·æ±‚æ•°é‡</span>
            <strong id="requestCount">0</strong>
            <span class="label" id="successRatio">æˆåŠŸç‡ 0%</span>
        </article>
        <article class="card">
            <span class="label">Prompt Tokens</span>
            <strong id="promptTokens">0</strong>
            <span class="label">ç´¯è®¡è¾“å…¥</span>
        </article>
        <article class="card">
            <span class="label">Completion Tokens</span>
            <strong id="completionTokens">0</strong>
            <span class="label">ç´¯è®¡è¾“å‡º</span>
        </article>
        <article class="card">
            <span class="label">Token æ€»é‡</span>
            <strong id="totalTokens">0</strong>
            <span class="label">å¹³å‡è€—æ—¶ <span id="avgLatency">0 ms</span></span>
        </article>
    </section>

    <section>
        <table>
            <thead>
            <tr>
                <th>å®Œæˆæ—¶é—´</th>
                <th>æ¨¡å‹</th>
                <th>Prompt</th>
                <th>Completion</th>
                <th>Total</th>
                <th>è€—æ—¶ (ms)</th>
                <th>çŠ¶æ€</th>
            </tr>
            </thead>
            <tbody id="metricsTableBody">
            <tr class="empty-state">
                <td colspan="7">æš‚æ— æ•°æ®ï¼Œè¯·å…ˆå‘èµ·ä¸€æ¬¡è¯·æ±‚æˆ–è°ƒæ•´æ—¶é—´èŒƒå›´ã€‚</td>
            </tr>
            </tbody>
        </table>
    </section>
</div>

<script>
    const statusBar = document.getElementById('statusBar');
    const requestCountEl = document.getElementById('requestCount');
    const successRatioEl = document.getElementById('successRatio');
    const promptTokensEl = document.getElementById('promptTokens');
    const completionTokensEl = document.getElementById('completionTokens');
    const totalTokensEl = document.getElementById('totalTokens');
    const avgLatencyEl = document.getElementById('avgLatency');
    const tableBody = document.getElementById('metricsTableBody');
    const apiKeyInput = document.getElementById('apiKeyInput');
    const saveKeyButton = document.getElementById('saveKey');
    const keyStatus = document.getElementById('keyStatus');
    const refreshButton = document.getElementById('refreshButton');
    const autoRefreshButton = document.getElementById('autoRefreshButton');
    const limitInput = document.getElementById('limitInput');
    const startInput = document.getElementById('startInput');
    const endInput = document.getElementById('endInput');

    let autoRefreshTimer = null;

    function setStatus(message, isError = false) {
        statusBar.textContent = message || '';
        statusBar.classList.toggle('error-text', isError);
    }

    function loadStoredKey() {
        const stored = localStorage.getItem('smithery-dashboard-key');
        if (stored) {
            apiKeyInput.value = stored;
            keyStatus.textContent = 'å·²ä»æµè§ˆå™¨å­˜å‚¨ä¸­åŠ è½½å¯†é’¥ã€‚';
        }
    }

    function storeKey() {
        const value = apiKeyInput.value.trim();
        if (!value) {
            keyStatus.textContent = 'è¯·è¾“å…¥æœ‰æ•ˆçš„å¯†é’¥ã€‚';
            keyStatus.classList.add('error-text');
            return;
        }
        localStorage.setItem('smithery-dashboard-key', value);
        keyStatus.textContent = 'å¯†é’¥å·²ä¿å­˜åˆ°æµè§ˆå™¨ï¼Œä»…å½“å‰è®¾å¤‡å¯è§ã€‚';
        keyStatus.classList.remove('error-text');
    }

    async function apiFetch(path) {
        const headers = new Headers();
        headers.append('Accept', 'application/json');
        const key = apiKeyInput.value.trim() || localStorage.getItem('smithery-dashboard-key');
        if (key) {
            headers.append('Authorization', `Bearer ${key}`);
        }
        const response = await fetch(path, { headers });
        if (!response.ok) {
            const message = await response.text();
            throw new Error(`æ¥å£è¯·æ±‚å¤±è´¥: ${response.status} ${message}`);
        }
        return response.json();
    }

    function toIsoString(value) {
        if (!value) {
            return null;
        }
        const date = new Date(value);
        if (Number.isNaN(date.getTime())) {
            return null;
        }
        return date.toISOString();
    }

    function formatNumber(value) {
        return Number(value || 0).toLocaleString();
    }

    function renderSummary(summary) {
        const requestCount = summary.request_count || 0;
        const successCount = summary.success_count || 0;
        const errorCount = summary.error_count || 0;
        const totalTokens = summary.total_tokens || 0;

        const successRate = requestCount === 0 ? 0 : Math.round((successCount / requestCount) * 100);

        requestCountEl.textContent = formatNumber(requestCount);
        successRatioEl.textContent = `æˆåŠŸç‡ ${successRate}% (å¤±è´¥ ${formatNumber(errorCount)} æ¬¡)`;
        promptTokensEl.textContent = formatNumber(summary.prompt_tokens || 0);
        completionTokensEl.textContent = formatNumber(summary.completion_tokens || 0);
        totalTokensEl.textContent = formatNumber(totalTokens);
        avgLatencyEl.textContent = `${Math.round(summary.average_latency_ms || 0)} ms`;
    }

    function renderTable(records) {
        tableBody.innerHTML = '';
        if (!records || records.length === 0) {
            const row = document.createElement('tr');
            row.classList.add('empty-state');
            const cell = document.createElement('td');
            cell.colSpan = 7;
            cell.textContent = 'æš‚æ— æ•°æ®ï¼Œè¯·å…ˆå‘èµ·ä¸€æ¬¡è¯·æ±‚æˆ–è°ƒæ•´æ—¶é—´èŒƒå›´ã€‚';
            row.appendChild(cell);
            tableBody.appendChild(row);
            return;
        }

        records.forEach(record => {
            const row = document.createElement('tr');
            if (record.status && record.status !== 'success') {
                row.classList.add('error');
                row.title = record.error_message || 'è¯·æ±‚å¤±è´¥';
            }

            const completedAt = record.completed_at ? new Date(record.completed_at).toLocaleString() : '-';

            row.innerHTML = `
                <td>${completedAt}</td>
                <td>${record.model || '-'}</td>
                <td>${formatNumber(record.prompt_tokens)}</td>
                <td>${formatNumber(record.completion_tokens)}</td>
                <td>${formatNumber(record.total_tokens)}</td>
                <td>${Math.round(record.duration_ms || 0)}</td>
                <td>${record.status || '-'}</td>
            `;

            tableBody.appendChild(row);
        });
    }

    async function refreshMetrics() {
        try {
            setStatus('æ­£åœ¨è¯·æ±‚æ•°æ®...');

            const params = new URLSearchParams();
            const startIso = toIsoString(startInput.value);
            const endIso = toIsoString(endInput.value);
            const limit = parseInt(limitInput.value, 10);

            if (startIso) params.set('start', startIso);
            if (endIso) params.set('end', endIso);
            if (Number.isFinite(limit)) params.set('limit', Math.max(1, Math.min(1000, limit)));

            const [summary, requests] = await Promise.all([
                apiFetch(`/metrics/summary?${params.toString()}`),
                apiFetch(`/metrics/requests?${params.toString()}`)
            ]);

            renderSummary(summary);
            renderTable(requests.data || []);
            const range = [];
            if (summary.window_start) range.push(`è‡ª ${new Date(summary.window_start).toLocaleString()}`);
            if (summary.window_end) range.push(`è‡³ ${new Date(summary.window_end).toLocaleString()}`);
            setStatus(range.join(' '));
        } catch (error) {
            console.error(error);
            setStatus(error.message, true);
        }
    }

    function toggleAutoRefresh() {
        if (autoRefreshTimer) {
            clearInterval(autoRefreshTimer);
            autoRefreshTimer = null;
            autoRefreshButton.textContent = 'å¼€å¯è‡ªåŠ¨åˆ·æ–°';
            setStatus('è‡ªåŠ¨åˆ·æ–°å·²å…³é—­');
        } else {
            autoRefreshTimer = setInterval(refreshMetrics, 30000);
            autoRefreshButton.textContent = 'å…³é—­è‡ªåŠ¨åˆ·æ–°';
            setStatus('è‡ªåŠ¨åˆ·æ–°å·²å¼€å¯ï¼Œæ¯ 30 ç§’æ›´æ–°ä¸€æ¬¡ã€‚');
        }
    }

    saveKeyButton.addEventListener('click', storeKey);
    refreshButton.addEventListener('click', refreshMetrics);
    autoRefreshButton.addEventListener('click', toggleAutoRefresh);

    document.addEventListener('visibilitychange', () => {
        if (document.hidden && autoRefreshTimer) {
            clearInterval(autoRefreshTimer);
            autoRefreshTimer = null;
            autoRefreshButton.textContent = 'å¼€å¯è‡ªåŠ¨åˆ·æ–°';
        }
    });

    loadStoredKey();
    refreshMetrics();
</script>
</body>
</html>

